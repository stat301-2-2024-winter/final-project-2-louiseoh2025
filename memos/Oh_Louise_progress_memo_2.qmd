---
title: "Progress Memo 2"
subtitle: |
  | Final Project 
  | Data Science 2 with R (STAT 301-2)
author: "Louise Oh"
date: today

format:
  html:
    toc: true
    embed-resources: true
    
execute:
  echo: false
  warning: false
  message: false

from: markdown+emoji 
reference-location: margin
citation-location: margin
---

::: {.callout-tip icon=false}
## Github Repo Link

[https://github.com/stat301-2-2024-winter/final-project-2-louiseoh2025.git](https://github.com/stat301-2-2024-winter/final-project-2-louiseoh2025.git)

:::

## Dataset Overview

The Mental Health In Pregnancy During COVID-19 Dataset^[Mental Health In Pregnancy During COVID-19 --- [https://www.kaggle.com/datasets/yeganehbavafa/mental-health-in-the-pregnancy-during-the-covid-19](https://www.kaggle.com/datasets/yeganehbavafa/mental-health-in-the-pregnancy-during-the-covid-19)] is aimed to understand the impact of COVID-19-related stresses on pregnant individuals and their infants and collected survey-based data across Canada as part of the Pregnancy during the COVID-19 Pandemic (PdP) project. This survey-based data allows for insights that can inform targeted interventions and support strategies to address the impact of COVID-19-related stresses on maternal and infant health.

::: {.callout-note icon="false"}
## Prediction Research Objective 

The goal is regression, specifically what the weight of the baby will be at birth based on the biological and psychological factors of mother and baby during a pandemic.

:::

## Target Variable

The target variable is `birth_weight`. This is a numerical variable in the form of double. The histogram below shows a unimodal distribution that is slightly skewed toward the left, but still nearly symmetric. The distribution looks nearly normal with outliers on both ends, but slightly more on the lower end, of the weight distribution. The original data has a distribution closer to a normal distribution compared to when it is transformed in some way, so no transformation is necessary.

## Data Splitting and Resampling

The cleaned pregnancy data was split into training (80%) and testing (20%) datasets. The split was stratified by the target variable, `birth_weight`. Repeated V-fold cross-validation with 5 folds and 3 repeats are performed on the training data. This technique randomly and repeatedly splits the data into 5 subsets of approximately equal size for training and validation. This provides a robust estimate of model performance and 5 sets of performance metrics. With this particular setup, each model will be trained and evaluated 15 times, covering various combinations of training and validation data. This is better than simply fitting and testing the models because it prevents overfitting and improves parameter and model accuracy by taking the uncertainty into account. See 1_*.R scripts for codes. 


## Recipes

There are two sets of recipes, 4 recipes in total. 

The first recipe is a kitchen sink recipe created with the following steps: impute any missing values of variables with less than 20% missing data (step_impute_knn), filter out variables have have zero variance (step_zv), center and scale all predictors (step_normalize), add dummy variables all categorical predictors (step_dummy), and remove uniqueID and original date variable (step_rm). This is the most basic recipe similar to a kitchen sink recipe. The kitchen sink recipe for nonparametric/tree models are revised with one-hot encoded to dummy variables. 

The second recipe is a more customized recipe with revised and additional steps after a simple EDA: add interaction terms between the threaten_baby_* variables and between the anxiety and depression levels which were related to each other (step_interact), transform postnatal_depression for normal distribution (step_sqrt). Similarly, the customized recipe for nonparametric/tree models are revised with one-hot encoded to dummy variables, and the interactions were removed since they do not affect tree-based models.

All recipes were prepped and baked, and were fitted to the different models which seemed to work. See 2_*.R scripts for codes. 


## Model Types

A null model fitted using the kitchen sink recipe for parametric models is used as the baseline model. Six other models are created for the prediction problem: linear regression, lasso regression, ridge regression, k-nearest neighbor, boosted tree, and random forest. Each of the models are fitted using the two different recipes. Each recipe was modified for parametric and nonparametric models. All models seemed to run. See 3_*.R scripts for codes. 


## Model Analysis 

```{r}
#| label: tbl-analysis
#| tbl-cap: "Initial Model Analysis"
#| echo: false
library(here)
load(here("results/assess_models.rda"))
tbl_rmse
```

@tbl-analysis shows the RMSE and its standard error for the baseline models and the 6 other models fitted/tuned using two distinct recipes, each customed for non-parametric and tree-based models. So far, the random forest model using the customized recipe seems to work best based on the lowest RMSE of 399.38 and its standard error. This is significantly better than the null model, which has an RMSE of 535.34. However, the customized recipes could be further refined since there is not much difference in model performance between the two recipes and the baseline recipe. See 4_*.R scripts for codes. 

## Final Model Assessment 

A best model will be chosen, and this model will be fitted using the whole training dataset instead of the folds. Afterwards, analysis will be performed on the final model using RMSE, RSQ, MSE, and MAPE. The final model used to predict the baby's birth weight for this project.

```{r}
#| label: tbl-metrics
#| tbl-cap: "Final Model Assessment Metrics"
#| echo: false

load(here("results/assess_final.rda"))
final_table
```

For now the random forest model using recipe 2 for tree-based models is the best model. @tbl-metrics shows the RMSE, RSQ, MAE, and MAPE of this final model fitted to the entire training dataset. 

```{r}
#| label: fig-assess
#| fig-cap: "Final Model Actual vs. Predicted Data"
#| echo: false
final_plot
```

@fig-assess plots the predicted birth weight by the actual birth weight of the random forest model using recipe 2 for tree-based models. 

These assessment tools will be used on the models fitted using finalized recipes for the final report. See 5_*.R scripts for codes. 

## Timeline

So far, I feel good about my progress since I have a placeholder for all models and everything seems to run. I have to update some codes and edit the recipes for the final report. Below is a rough timeline to have my project completed on time. 

- February 29: finalize the recipes and models, compare models
- March 1: decide on final model and analyze its performance
- March 3: write a draft of the final report and have any questions answered by Prof/TAs
- March 5: write the executive summary and update github repo and README documents
- March 6: proofread and submit final project
